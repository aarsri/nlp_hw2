{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NLP HW2: Parsing\n",
        "Last Updated: Sep 25 3:20 PM"
      ],
      "metadata": {
        "id": "H9UVrLjSDK3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jdc\n",
        "import jdc"
      ],
      "metadata": {
        "id": "nysaMbFqEIk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://raw.githubusercontent.com/aarsri/nlp_hw2/refs/heads/main/utils.py\n",
        "!wget -nc https://raw.githubusercontent.com/aarsri/nlp_hw2/refs/heads/main/trees.py"
      ],
      "metadata": {
        "id": "jVAS8M5CKkc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Bi-LSTM POS Tagger\n",
        "In this part, you will build a part-of-speech tagger using the bidirectional LSTM architecture."
      ],
      "metadata": {
        "id": "XTybDZltGwxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import random\n",
        "import pickle\n",
        "import nltk\n",
        "from nltk.corpus import treebank\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "nltk.download('treebank')\n",
        "brown = list(treebank.tagged_sents())"
      ],
      "metadata": {
        "id": "j0OaEhyyDN6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[4 points]** Implement a **bidirectional** LSTM with embedding size 128 and hidden size 256 using torch.nn.LSTM with appropriate parameters set. Remember that PyTorch's cross entropy loss includes softmax."
      ],
      "metadata": {
        "id": "gKFCXjXIHFHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BiLSTMTagger(nn.Module):\n",
        "\tdef __init__(self, data, embedding_dim, hidden_dim):\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.words = None\n",
        "\t\tself.tags = None\n",
        "\t\t\"\"\"TODO: Populate self.words and self.tags as two vocabulary objects using the Vocab class in utils.py.\n",
        "\t\tThis will allow you to easily numberize and denumberize the word vocabulary as well as the tagset.\n",
        "\t\tMake sure to add <UNK> self.words.\"\"\"\n",
        "\t\tself.embedding_dim = embedding_dim\n",
        "\t\tself.hidden_dim = hidden_dim\n",
        "\t\t\"\"\"\tTODO: Initialize layers.\"\"\"\n",
        "\t\t# embedding\n",
        "\t\t# lstm\n",
        "\t\t# dropout\n",
        "\t\t# W_out\n",
        "\t\traise NotImplementedError"
      ],
      "metadata": {
        "id": "RZLxOmiHDkj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%add_to BiLSTMTagger\n",
        "def forward(self, sentence):\n",
        "\t\"\"\"\tTODO: Pass the sentence through the layers of the model.\n",
        "\t\t* Because we are using the built-in LSTM, we can pass in an entire sentence rather than iterating through the tokens.\n",
        "\t\t* IMPORTANT: Because we are dealing with a full sentence now, we have to do minor reshaping.\n",
        "\t\t\t* Before passing the embeddings into the LSTM, we have to do `embeddings.view(len(sentence), 1, -1)`\n",
        "\t\t\t* Before passing the LSTM output into dropout, we have to do `lstm_out.view(len(sentence), -1)`\n",
        "\t\t* Return the output scores from the model (pre-softmax). This will be of shape: len(sentence) x total number of tags, meaning each row corresponds to a word, and the values in each row are the scores for all possible POS tags for that word.\"\"\"\n",
        "\traise NotImplementedError"
      ],
      "metadata": {
        "id": "m4_k6KXqERUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%add_to BiLSTMTagger\n",
        "def predict(self, scores):\n",
        "\t\"\"\"\tTODO: Return the most likely tag sequence.\n",
        "\t\t* When the dim argument is provided, torch.argmax(input, dim) returns a tensor containing the indices of the maximum values along that specified dimension.\n",
        "\t\t* Since each row of scores corresponds to a different word, and each column corresponds to a different tag, specificy dim=1 (take max along columns).\"\"\"\n",
        "\traise NotImplementedError"
      ],
      "metadata": {
        "id": "lDuGWc36E0FL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[3 points]** Write **training** and **evaluation** procedures. These should be similar to HW1 Part 2 and 3.\n",
        "- For debugging purposes only, shorten the training data by commenting out the train_sents += brown line. Accuracy will be high because the train set is otherwise a combination of ATIS and BROWN, while the test set is ATIS. Commenting out this line will still have the model trained and tested on ATIS, yielding a high accuracy.  However, it will not be generalized well enough to do the free response.\n"
      ],
      "metadata": {
        "id": "hQ9dWqMWHONW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%add_to BiLSTMTagger\n",
        "def fit(self, data, lr=0.01, epochs=5):\n",
        "\t\"\"\"\tTODO: This function is very similar to fit() from HW1.\"\"\"\n",
        "\n",
        "\t# 1. Initialize the optimizer. Use `torch.optim.Adam` with `self.parameters()` and `lr`.\n",
        "\n",
        "\t# 2. Set a loss function variable to `nn.CrossEntropyLoss()`. It includes softmax.\n",
        "\n",
        "\t# 3. Loop through the specified number of epochs.\n",
        "\n",
        "\t#\t 1. Put the model into training mode using `self.train()`.\n",
        "\n",
        "\t#\t 2. Shuffle the training data using random.shuffle().\n",
        "\n",
        "\t#\t 3. Initialize variables to keep track of the total loss (`total_loss`) and the total number of tokens (`total_tokens`).\n",
        "\n",
        "\t#\t 4. Loop over each sentence in the training data.\n",
        "\n",
        "\t#\t \t1. Produce a numberized sequence of the words in the sentence. Make words lowercase first, and convert the sequence to a tensor using something like: `torch.tensor(idxs, dtype=torch.long)`.\n",
        "\n",
        "\t#\t\t2. Prepare the target labels using something like: `targets = torch.tensor([self.tags.numberize(t) for t in tags], dtype=torch.long)`\n",
        "\n",
        "\t#\t \t3. Call `self.zero_grad()` to clear any accumulated gradients from the previous update.\n",
        "\n",
        "\t#\t \t4. Pass the prepared sequence into the model by doing `self(sentence)` to obtain scores. This automatically calls forward().\n",
        "\n",
        "\t#\t\t5. Calculate loss, passing in the output scores and the true target labels.\n",
        "\n",
        "\t#\t \t6. Call `loss.backward()` to compute gradients.\n",
        "\n",
        "\t#\t\t7. Apply gradient clipping to prevent exploding gradients. Use `torch.nn.utils.clip_grad_norm_()` with `self.parameters()` and a `max_norm` of 5.0.\n",
        "\n",
        "\t#\t\t8. Call `optimizer.step()` to update the model parameters using the computed gradients.\n",
        "\n",
        "\t#\t\t9. Add `loss.item() * len(targets)` to `total_loss`.\n",
        "\n",
        "\t#\t\t10. Add `len(targets)` to `total_tokens`.\n",
        "\n",
        "\t#\t5. Compute the average loss per token by dividing `total_loss / total_tokens`.\n",
        "\n",
        "\t#\t6. For debugging, it will be helpful to print the average loss per token and the runtime after each epoch. Average loss per token should always decrease epoch to epoch.\n",
        "\n",
        "\traise NotImplementedError"
      ],
      "metadata": {
        "id": "4uNfBMQxFxej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%add_to BiLSTMTagger\n",
        "def evaluate(self, data):\n",
        "\t\"\"\"\tTODO: Iterating over the sentences in the data, calculate POS tagging accuracy.\n",
        "\t\t* Use `self.eval()` and `with torch.no_grad()` so that the model is not trained during evaluation.\n",
        "\t\t* Prepare the sequence and target labels as in fit().\n",
        "\t\t* Use self.predict() to get the predicted tags, and then check if it matches the real next character found in the data.\n",
        "\t\t* Divide the total correct predictions by the total number of tokens to get the final accuracy.\"\"\"\n",
        "\traise NotImplementedError"
      ],
      "metadata": {
        "id": "tlJSUs6bGROz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[1 point]** Report **loss per epoch** and **accuracy**. For full credit, accuracy must be at least 92% on val.pos and test.pos. Include your **saved model** in the submission files.\n",
        "- Because the dataset is small, scores from randomly initialized runs can have greater variance. If you're close to this score (e.g., 90%), there is likely not a bug and instead you had an unlucky run. You can run it again if you have time or comment that you believe the code is correct.\n"
      ],
      "metadata": {
        "id": "RCDNyNOjHZPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  \"\"\"TODO: (reference HW1 part3.py)\n",
        "\t  * Use read_pos_file() from utils.py to read train.pos, val.pos, and test.pos.\n",
        "\t  * Initialize the model with training data, embedding dim 128, and hidden dim 256.\n",
        "\t  * Train the model, calling fit(), on the training data.\n",
        "\t  * Test the model, calling evaluate(), on the validation and test data.\n",
        "\t  * Predict outputs for the first ten examples in test.pos.\n",
        "\t  * Remove all instances of `raise NotImplementedError`!\"\"\"\n",
        "  raise NotImplementedError\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "id": "a2DrvtH2GYqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[2 points]** Free response: For the first 10 sentences of test.pos, **report the POS tags predicted by your model.**\n",
        "- What works well, and what doesn't?\n",
        "> TODO\n",
        "- For words tagged incorrectly, why do you think it happens, and what tag do they tend to get?\n",
        "> TODO\n",
        "- Think about micro- and macro-level tags (e.g., is it tagging NNS as NN, or VBD as NN, and which one is worse?).\n",
        "> TODO\n"
      ],
      "metadata": {
        "id": "c-Z64TFuHqYc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Probabilistic Context Free Grammar\n",
        "In this part, you will learn a PCFG given training data annotated with parse trees."
      ],
      "metadata": {
        "id": "TRcIs3YjIGf9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import trees\n",
        "import fileinput\n",
        "import collections\n",
        "import re\n",
        "\"\"\"You should not need any other imports, but you may import anything that helps.\"\"\"\n",
        "\n",
        "counts = collections.defaultdict(collections.Counter)"
      ],
      "metadata": {
        "id": "0I5vMzJ4MGbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[4 points]** Write code to read in trees and to count all the rules used in each tree. **Terminal nodes should be POS tags rather than words** to allow us to use the POS tagger. This means the grammar must contain a set of rules mapping each nonterminal POS tags in the PTB tag set to a terminal POS tag:\n",
        "```\n",
        "DT -> DT_t\n",
        "NN -> NN_t\n",
        "NNS -> NNS_t\n",
        "```\n"
      ],
      "metadata": {
        "id": "Tx8PLiCSK0Jr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_rules():\n",
        "  \"\"\"TODO: Collect all the tree branching rules used in the parses in train.trees, and count their frequencies.\n",
        "    * Use trees.Tree.from_str(), bottomup(), and other helpful functions from trees.py.\n",
        "    * Goal: end up with three dictionaries, counts, probs, and cfg.\n",
        "      * counts has entries count[LHS][RHS], like count[NP][(DT, NN)].\n",
        "      * probs has entries prob[LHS][RHS] = count[LHS][RHS] / sum(count[LHS].values())\n",
        "      * cfg simply has the rules of the grammar, stored using whichever structure is usable to you for your CKY implementation. For instance, indexing by RHS may be easier to look up for CKY (cfg[RHS][LHS].\n",
        "      * To include terminal words as POS_t (e.g., NN_t) as you're constructing the CFG:\n",
        "        if len(node.children) == 1: # terminal rules\n",
        "          rhs = (node.label.split('_')[-1]+'_t',) # rhs = (NN_t,)\n",
        "  \"\"\"\n",
        "  raise NotImplementedError"
      ],
      "metadata": {
        "id": "QReJeAGHLMYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[3 points]** Write code to compute the conditional probability of each rule and **print the PCFG in a readable format**, such as:\n",
        "```\n",
        "NP -> DT NN # 0.5\n",
        "NP -> DT NNS # 0.5\n",
        "```"
      ],
      "metadata": {
        "id": "EqcVdullK89D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_pcfg():\n",
        "  raise NotImplementedError"
      ],
      "metadata": {
        "id": "dv8X83skLM-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[3 points]** Running the code on train.trees, **report**:\n",
        "- How many unique rules are there?\n",
        "> TODO\n",
        "- What are the top five most frequent rules, and how many times did each occur?\n",
        "> TODO\n",
        "- What are the top five highest-probability rules with left-hand side NP, and what are their probabilities?\n",
        "> TODO\n",
        "- **Free Response**: Did the most frequent rules surprise you? Why or why not?\n",
        "> TODO\n"
      ],
      "metadata": {
        "id": "RwlFtXGULE_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  raise NotImplementedError\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "id": "lbEBpSxPKwMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3: CKY Parsing\n",
        "In this part, you will implement the CKY parsing algorithm."
      ],
      "metadata": {
        "id": "rwt8mwdwNm62"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[4 points]** Implement a CKY parser that takes your grammar and a set of POS tags as input, and outputs the highest-probability parse. If you can't find any parse, output a blank line. Use **log-probabilities** to avoid underflow."
      ],
      "metadata": {
        "id": "7PHqLIdiNuVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_cky():\n",
        "  \"\"\"\n",
        "  Goal: Highest-probability parse using a PCFG, with POS tags (from your BiLSTM)\n",
        "        as the terminal layer.\n",
        "\n",
        "  Inputs:\n",
        "    - cfg / counts / probs: representations of your PCFG\n",
        "    - true POS tags or POS tags as the output of a trained BiLSTM POS tagger\n",
        "\n",
        "  Output:\n",
        "    - For each sentence line from stdin or a file, print one bracketed tree to stdout\n",
        "      (or an empty line if no parse) with its probability.\n",
        "\n",
        "  Keep these three phases conceptually separate:\n",
        "    (1) POS tagging + diagonal initialization\n",
        "    (2) CKY dynamic program over spans (big nested loop)\n",
        "    (3) Root selection + backpointer reconstruction + printing\n",
        "\n",
        "  You are free to choose your exact data structures, as long as you can:\n",
        "    - store best scores for labels over spans\n",
        "    - remember how each best item was built (backpointers)\n",
        "    - reconstruct a bracketed tree string at the end\n",
        "\n",
        "  -----------------------------------------------------------------------------\n",
        "  0) GRAMMAR + PROBABILITIES + <unk>\n",
        "  -----------------------------------------------------------------------------\n",
        "  * When reading a sequence of POS tags, map each tag to itself if in vocab,\n",
        "    or else to a special token like \"<unk>\" (but keep original for printing).\n",
        "  * After reconstruction, print the original word as the leaf instead.\n",
        "  * Use log probabilities to avoid underflow:\n",
        "    score = log P(A -> B C) + score(left) + score(right)\n",
        "\n",
        "  -----------------------------------------------------------------------------\n",
        "  1) READ ONE SENTENCE LINE → TOKENS → POS TAGS → DIAGONAL INIT\n",
        "  -----------------------------------------------------------------------------\n",
        "  - Read lines from train.pos as (word, tag) tuples using read_pos_files().\n",
        "  - Run your BiLSTM POS tagger on the words to get one POS per token.\n",
        "    * Hint: to confirm that CKY works, first just use the true POS tags rather than running it through your tagger.\n",
        "\n",
        "  - Create two core tables for CKY (choose your own structures, examples below):\n",
        "      chart:   stores best scores for labels over spans\n",
        "              indexable by span (i, k) and then by label\n",
        "      backptr: stores how that best label@span was formed\n",
        "              (for terminals: the terminal tag; for binary: (left_label, split_index, right_label))\n",
        "\n",
        "    Example shapes (you can pick others):\n",
        "      chart[(i, k)][label]  -> best_score (log-prob or prob)\n",
        "      backptr[(i, k)][label] -> for terminal: stored tag\n",
        "                                for binary: (left_label, j, right_label)\n",
        "\n",
        "  - Diagonal initialization (length-1 spans [i, i+1)):\n",
        "      For each position i:\n",
        "        * Use the POS tag(s) for token i as candidate preterminals.\n",
        "        * Record best scores per POS at (i, i+1).\n",
        "        * Record backptr so reconstruction can print \"(POS word)\".\n",
        "\n",
        "  -----------------------------------------------------------------------------\n",
        "  2) CKY DYNAMIC PROGRAM (THE BIG NESTED LOOP)\n",
        "  -----------------------------------------------------------------------------\n",
        "  The standard CKY fill uses three nested loops over span length, start index,\n",
        "  and split point. Conceptually:\n",
        "\n",
        "    for span_length in 2..n:\n",
        "      for i in 0..(n - span_length):\n",
        "        k = i + span_length\n",
        "        initialize chart[(i, k)] and backptr[(i, k)] (empty)\n",
        "\n",
        "        for j in (i+1)..(k-1):   # split index\n",
        "          # Consider all ways to combine a left piece (i, j) with a right piece (j, k)\n",
        "          for each left_label in chart[(i, j)]:\n",
        "            for each right_label in chart[(j, k)]:\n",
        "              # Check if any rule A -> left_label right_label exists in your PCFG\n",
        "              for each A with P(A -> left_label right_label):\n",
        "                candidate_score = chart[(i, j)][left_label] + \\\n",
        "                                  chart[(j, k)][right_label] + \\\n",
        "                                  log P(A -> left_label right_label)\n",
        "                if candidate_score is better than current chart[(i, k)][A]:\n",
        "                    update chart[(i, k)][A] = candidate_score\n",
        "                    set backptr[(i, k)][A] = (left_label, j, right_label)\n",
        "\n",
        "  Notes:\n",
        "    - Only binary rules are considered here (CNF).\n",
        "    - Keep everything in log-space abd use addition rather than multiplication.\n",
        "\n",
        "  -----------------------------------------------------------------------------\n",
        "  3) ROOT SELECTION, RECONSTRUCTION, PRINTING\n",
        "  -----------------------------------------------------------------------------\n",
        "  - After the table is filled, focus on the full span (0, n).\n",
        "    * Prefer the designated start symbol (e.g., 'TOP') if present at (0, n).\n",
        "    * If 'TOP' is not present, produce an empty parse.\n",
        "\n",
        "  - Reconstruct the tree via backpointers:\n",
        "    * Define a recursive function:\n",
        "        reconstruct(label, i, k):\n",
        "          bp = backptr[(i, k)][label]\n",
        "          if bp is a terminal word (or \"<unk>\"):\n",
        "              return \"(label word_or_original)\"\n",
        "          else:\n",
        "              (left_label, j, right_label) = bp\n",
        "              left_subtree  = reconstruct(left_label,  i, j)\n",
        "              right_subtree = reconstruct(right_label, j, k)\n",
        "              return f\"(label {left_subtree} {right_subtree})\"\n",
        "\n",
        "    * Ensure terminals print the original word here rather than POS tags.\n",
        "\n",
        "  - Output:\n",
        "    * Print the bracketed tree string for each input sentence (or an empty line\n",
        "      if no parse), one sentence per line.\n",
        "    * Print the final score for TOP at (0, n) as a log-prob.\n",
        "\n",
        "  -----------------------------------------------------------------------------\n",
        "  4) PRACTICAL TIPS / DECISIONS (YOU CHOOSE)\n",
        "  -----------------------------------------------------------------------------\n",
        "  - Data structures:\n",
        "      * dict-of-dicts is fine; you can also use defaultdicts.\n",
        "      * You can index chart/backptr by tuples (i, k) or use a 2D list.\n",
        "\n",
        "  - Efficiency:\n",
        "      * Iterate only over labels that actually occur in the subspans.\n",
        "      * If your PCFG is stored by RHS (B, C) -> {A: prob}, you can quickly find\n",
        "        candidate parents A for a given pair (B, C).\n",
        "\n",
        "  - Scores:\n",
        "      * Prefer log-space: add logs instead of multiplying probabilities.\n",
        "\n",
        "  - Debugging:\n",
        "      * Print the diagonal cells after initialization to verify POS entries.\n",
        "      * For a tiny sentence (2–3 words), print intermediate chart cells per length.\n",
        "      * If reconstruction fails, check that backptr entries are actually written\n",
        "        whenever you write a score.\n",
        "\n",
        "  -----------------------------------------------------------------------------\n",
        "  5) MINIMUM I/O LOOP\n",
        "  -----------------------------------------------------------------------------\n",
        "  for each line from stdin:\n",
        "    tokens = line.split()\n",
        "    tags = run_pos_tagger(orig_tokens)\n",
        "\n",
        "    initialize empty chart/backptr\n",
        "\n",
        "    # diagonal init\n",
        "    for i in range(n):\n",
        "      fill chart[(i, i+1)] and backptr[(i, i+1)] with POS entries\n",
        "\n",
        "    # CKY nested loops (length, start i, split j) using binary PCFG rules\n",
        "    fill chart/backptr for spans of length >= 2\n",
        "\n",
        "    if TOP in chart[(0, n)]:\n",
        "        tree_str = reconstruct('TOP', 0, n)   # bracketed\n",
        "        print(tree_str)\n",
        "        print(logprob_of_TOP_to_stderr)\n",
        "    else:\n",
        "        print(\"\")  # empty line if no parse\n",
        "  \"\"\"\n",
        "  raise NotImplementedError()"
      ],
      "metadata": {
        "id": "_5xDOfWuNz5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[1 point]** Test the CKY parser with the test set with **gold POS tags**. **Print** the parse trees for the **first 10 test sentences** (use empty line for no parse). For full credit, these should match or be similar to the true parses in test.trees."
      ],
      "metadata": {
        "id": "msTjbIrvO40p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_parser():\n",
        "  raise NotImplementedError()\n",
        "\n",
        "test_parser()"
      ],
      "metadata": {
        "id": "VZo8CB5DO_NP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[2 points]** Integrate your **Bi-LSTM tagger** to assign POS tags to the words of any input sentence before passing it in to your CKY parser."
      ],
      "metadata": {
        "id": "1rxWxJiEPHq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def assign_tags():\n",
        "  raise NotImplementedError"
      ],
      "metadata": {
        "id": "MKrdEKBNQUy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[1 point]** Test the full pipeline (**input → tagger → CKY**). **Print** the parse trees for the **first 10 test sentences** (use empty line for no parse) using the predicted POS tags."
      ],
      "metadata": {
        "id": "teR_j7R3Qn0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_pipeline():\n",
        "  raise NotImplementedError()\n",
        "\n",
        "test_pipeline()"
      ],
      "metadata": {
        "id": "BHxn4_yQQixu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[2 points]** Free response: For the first 10 sentences of test.pos…\n",
        "- Is there a difference in which sentences it fails to parse given gold tags vs. your tagger's outputs? Why or why not?\n",
        "> TODO\n",
        "- Which ones does it do well on (i.e., match the true parse in test.trees), and why?\n",
        "> TODO\n",
        "- Which ones does it do poorly on (but still produces a parse), and why?\n",
        "> TODO\n"
      ],
      "metadata": {
        "id": "KzmDfxlxQx1e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Congratulations! That's a wrap on HW2. Onto neural methods and greater generalizability.**"
      ],
      "metadata": {
        "id": "o0V01er4RDAh"
      }
    }
  ]
}